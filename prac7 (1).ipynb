{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9df9eb-ebc5-4155-921c-8509353bca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83507637-33d4-46a9-a1aa-1d9fa820541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\r\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5afed7ff-51f0-43ea-b598-5fa257bdeb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"\"\"Machine learning is the science of getting computers to learn from data without being explicitly programmed.\n",
    "It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e727c625-5a8b-4d25-bf74-c2c373abe912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', 'is', 'the', 'science', 'of', 'getting', 'computers', 'to', 'learn', 'from', 'data', 'without', 'being', 'explicitly', 'programmed', '.', 'It', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'based', 'on', 'the', 'idea', 'that', 'systems', 'can', 'learn', 'from', 'data', ',', 'identify', 'patterns', 'and', 'make', 'decisions', 'with', 'minimal', 'human', 'intervention', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=word_tokenize(document)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb2285eb-9448-4210-b200-493bc7605e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('science', 'NN'), ('of', 'IN'), ('getting', 'VBG'), ('computers', 'NNS'), ('to', 'TO'), ('learn', 'VB'), ('from', 'IN'), ('data', 'NNS'), ('without', 'IN'), ('being', 'VBG'), ('explicitly', 'RB'), ('programmed', 'VBN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('branch', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('idea', 'NN'), ('that', 'IN'), ('systems', 'NNS'), ('can', 'MD'), ('learn', 'VB'), ('from', 'IN'), ('data', 'NNS'), (',', ','), ('identify', 'NN'), ('patterns', 'NNS'), ('and', 'CC'), ('make', 'VB'), ('decisions', 'NNS'), ('with', 'IN'), ('minimal', 'JJ'), ('human', 'JJ'), ('intervention', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "posts=pos_tag(tokens)\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670ae1bd-f4c1-48c3-a1fd-2cea5c34af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a538bf2-b326-4bc9-be7e-3164ea41804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', 'science', 'getting', 'computers', 'learn', 'data', 'without', 'explicitly', 'programmed', 'branch', 'artificial', 'intelligence', 'based', 'idea', 'systems', 'learn', 'data', 'identify', 'patterns', 'make', 'decisions', 'minimal', 'human', 'intervention']\n"
     ]
    }
   ],
   "source": [
    "stop=set(stopwords.words('english'))\n",
    "filtered=[word for word in tokens if word.lower() not in stop and word.isalpha()]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9da4beb-57af-4ec1-b771-b2c20fe738f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "976e54fc-bbda-48ba-ae8c-3764143cc5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machin', 'learn', 'scienc', 'get', 'comput', 'learn', 'data', 'without', 'explicitli', 'program', 'branch', 'artifici', 'intellig', 'base', 'idea', 'system', 'learn', 'data', 'identifi', 'pattern', 'make', 'decis', 'minim', 'human', 'intervent']\n"
     ]
    }
   ],
   "source": [
    "stemmer=PorterStemmer()\n",
    "stemmed=[stemmer.stem(word) for word in filtered]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6797b9ca-0fe2-44aa-9651-eab11d8a33da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', 'science', 'getting', 'computer', 'learn', 'data', 'without', 'explicitly', 'programmed', 'branch', 'artificial', 'intelligence', 'based', 'idea', 'system', 'learn', 'data', 'identify', 'pattern', 'make', 'decision', 'minimal', 'human', 'intervention']\n"
     ]
    }
   ],
   "source": [
    "lem=WordNetLemmatizer()\n",
    "lems=[lem.lemmatize(word) for word in filtered]\n",
    "print(lems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51ed82b9-02b8-46b0-92fe-1cab841b43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41c1edd5-b72e-41c2-b269-14bc9000a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Machine learning is a branch of artificial intelligence.\",\n",
    "    \"It allows computers to learn from data.\",\n",
    "    \"Artificial intelligence and data science are evolving fields.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "059ad330-156b-4a6a-8d87-7337e670e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()\n",
    "matrix=vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e36dceb-eeeb-406e-878d-f149ce88f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ef37016-cfd2-41e4-ae03-dc0b6e71871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(matrix.toarray(),columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7975393-48d6-4a2c-b02a-e893a75f3f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     allows       and       are  artificial    branch  computers      data  \\\n",
      "0  0.000000  0.000000  0.000000    0.306504  0.403016   0.000000  0.000000   \n",
      "1  0.389888  0.000000  0.000000    0.000000  0.000000   0.389888  0.296520   \n",
      "2  0.000000  0.385323  0.385323    0.293048  0.000000   0.000000  0.293048   \n",
      "\n",
      "   evolving    fields      from  intelligence        is        it     learn  \\\n",
      "0  0.000000  0.000000  0.000000      0.306504  0.403016  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.389888      0.000000  0.000000  0.389888  0.389888   \n",
      "2  0.385323  0.385323  0.000000      0.293048  0.000000  0.000000  0.000000   \n",
      "\n",
      "   learning   machine        of   science        to  \n",
      "0  0.403016  0.403016  0.403016  0.000000  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.389888  \n",
      "2  0.000000  0.000000  0.000000  0.385323  0.000000  \n"
     ]
    }
   ],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef47f4bb-1ec1-4676-8e5f-a37b01c7834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\r\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\r\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\r\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\r\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93360e5-2d03-4471-be37-ccf5165d2691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
